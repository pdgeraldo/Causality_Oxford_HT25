---
title: "Structural Causal Model"
author: "Pablo Geraldo Bast√≠as"
logo: "https://fundit.fr/sites/default/files/styles/max_650x650/public/institutions/capture-decran-2023-07-07-162216.png?itok=1CkwlJEu"
include-in-header:
  - text: |
      <style>
      .reveal .slide-logo {
        max-height: unset;
        height: 100px;
      }
      </style>
footer: "Structural Causal Model"
date: 01/27/2025
date-format: long
format: 
  revealjs:
    theme: simple
    width: 1600
    height: 900
    transition: slide
    slide-number: c/t
    chalkboard: true
    auto-stretch: false
callout-appearance: simple
---


# Outline {background-color="#17a091"}

\newcommand\indep{\perp\!\!\!\perp}
\newcommand\nindep{\not\!\perp\!\!\!\perp}


## Recap from previous session

* We studied the difference between [**seeing**]{.fragment .highlight-red} (the focus of Stats/ML) and [**doing**]{.fragment .highlight-red} (the focus of causal inference)

* We studied the importance of using the formal language  of potential outcomes to:
  
  + clarify *what do we want to know* ([**estimand**]{style="color:blue"})
  
  + identify *reasons for discrepancies* between what we observe and our target ([**bias**]{style="color:blue"}) 
  
  + formalize *what needs to be true*  for our estimand to be identified with a given *estimator* ([**assumptions**]{style="color:blue"})
  
  
* We studied the role of **randomisation** to identify causal effects [**by design**]{style="color:green"}.

. . .

But what do we do when we have *less than perfect* experiments?

. . .

And how to assess our assumptions with *observational data*?


## Lecture 2: From causal assumptions to causal models

When introducing potential outcomes, we emphasized that it is not the method what makes our results causal, but our [**assumptions**]{style="color:red"}

. . .

However, what makes our assumptions credible?

. . .

To answer that question, we need to be explicit about our **model**, i.e., how do we believe the world works

. . . 

+ In this lecture we will introduce a framework that makes formulating such models easy and intuitive

+ We will develop the machinery needed to be explicit about our model and derive its testable implications

+ Potential outcomes appear now, not as *primitives*, but as quantities *derived* from a more fundamental entity: a [*structural model*]{style="color:green"}

. . . 

Researchers often leave the model implicit and unspecified. I will argue that making it explicit can greatly improve transparency in scientific communication

# Graphical models {background-color="#17a091"}

## Why graphical models?

Formally, potential outcomes are sufficient to specify our estimand, sources of bias, and assumptions needed for causal identification.

. . .

However, assessing the plausibility of identification assumptions rely on researchers being able to reason about (conditional) independence between possibly *counterfactual* variables. 

. . .

Any ideas on [how to assess]{style="color:blue"} the assumption about the *conditional* independence of the **potential outcomes** with respect to the treatment, without randomization?

. . .

We can certainly *understand* the statement saying that the treatment is assigned **as-if random** adjusting for covariates. But what about its plausibility?

---

## Why graphical models?
### Assessing ignorability


When we say the treatment assignment is [**strongly ignorable**]{style="color:red"} we are stating that $P(Y_d|D=d) = P(Y_d)$, but we never get to observe the full distribution of potential outcomes!


* What type of criteria should we use when discussing others' causal claims? 

* What kind of criteria should we use in our own research to judge if we are getting what we are looking for?

Here is where DAGs shine, offering a graphical criteria that is equivalent to the unconfoundedness statement, the [*backdoor criterion*]{style="color:red"}.


## Structural Causal Model (SCM)

Unifying approach to causal inference, developed by Pearl, Robins, among others, following early developments by Wright:

* (Non-parametric) Structural Equation Models
  
* Generalization of the path analysis and SEM you might be familiar with

* Graphical representation using Directed Acyclic Graphs (DAGs)

* Potential Outcomes are [**derived** from]{style="color:blue"} a SCM

* Transparent representation of **qualitative assumptions**

* Testable implications of our model of the data generating process
---


## Directed Acyclic Graphs (DAGs)

Probabilistic graphical models are mathematical objects that represent relations among variables (probability factorization) 

They are compounded by two ingredients: [**nodes**]{style="color:green"} (vertices) and [**edges**]{style="color:green"} (links)

Directed Acyclic Graphs (DAGs) are one class of graphical models, with the following characteristics:

. . .

* [**Directed**]{.fragment .highlight-blue}: The edges point *from* one variable *to* another variable

* [**Acyclic**]{.fragment .highlight-blue}: The paths in the graph flow in certain direction, if you follow the edges you cannot arrive back to the starting point

* [**Graph**]{.fragment .highlight-blue}: well, you get it!

. . .

:::{.callout-warning}
## Important! Under certain conditions, a DAG can be causally interpreted, in which case we talk about "causal DAGs" or causal diagrams

Basically, this happen when we assume that no pair of nodes share a common ancestor that is not included in the DAG
:::


---

## Paths

We can go from one variable to another following a [*path*]{style="color:blue"} along the edges 

When you can traverse a path without colliding into an edge in the opposite direction we call it a [**connecting path**]{style="color:green"} that transmit information

When you encounter an edge pointing into the opposite direction along a path we call it a [**blocking path**]{style="color:red"} that do not transmit information


:::{.callout-warning}
## Faithfulness
$d-$connection in the graph implies association between variables in the data, while $d-$separation implies their independence
:::

Keep in mind: sometimes it is **not** about the variables (alone), but about the paths that, together, they create!

## Building blocks

* A [**chain**]{style="color:green"}, in which you can travel from $X$ to $Y$ through $M$, is a $d-$connected path. All variables are [*marginally associated*]{style="color:green"}

$$X \color{green}{\rightarrow} M \color{green}{\rightarrow} Y$$

* A [**fork**]{style="color:green"}, in which you can go from a common cause $W$ to both $X$ and $Y$ is a $d-$connected path. All variables are [*marginally associated*]{style="color:green"}


$$X \color{green}{\leftarrow} W \color{green}{\rightarrow} Y$$

* A [**collider**]{style="color:red"}, in which you can't go from $X$ to $Y$ due to two edges pointing into a third variable $C$, is a $d-$separated path. $X$ and $Y$ are [*marginally independent*]{style="color:red"}
 

$$X \color{red}{\rightarrow} C \color{red}{\leftarrow} Y$$


## Flipping the switch

* When you adjust for the intermediate variable $M$ in a chain, $X$ and $Y$ become $d-$separated and, therefore, [*conditonally independent*]{style="color:red"}: 

$$X \rightarrow \boxed{M} \color{red}{\rightarrow} Y$$

* When you adjust for the common cause $W$ in a fork, $X$ and $Y$ become $d-$separated and, therefore, [*conditionally independent*]{style="color:red"}: 

$$X \color{red}{\leftarrow} \boxed{W} \color{red}{\rightarrow} Y$$

* When you adjust for a collider variable $C$, the pair $X$ and $Y$ become $d-$connected and, therefore, [*conditionally associated*]{style="color:green"}: 

$$X \color{green}{\cdots} \boxed{C} \color{green}{\cdots} Y$$

## Alternative representations

<br>

A graphical model is [one possible]{style="color:green;"} representation of a causal system. 

In the [Structural Causal Model]{style="color:blue;"}, we will sometimes appeal to other alternative, but equivalent, representations. Depending on what do you want to achieve, different representations may be more or less useful

In particular, we will look at:

* A set of [structural equations]{.fragment .highlight-blue} indicating functional dependencies between variables

* A [truncated factorization]{.fragment .highlight-blue} of the joint probability distribution of the variables in the graph:

$$P(X_1, X_2, \dots, X_n) = \prod_i P(X_i|pa_i)$$

:::aside
This is call a "Markov condition": the future is independent of the remote past conditional on the immediate past!
:::


## Alternative representations: chaining paths

<br>

:::{.columns}

:::{.column width=50%}

[**Graphical model**]{style="color:blue;"}

$$X \rightarrow M \rightarrow Y$$

<br>

| [**Structural Equations**]{style="color:blue;"} |
|-----|
| $X = f_x(U_x)$ |
| $M = f_m(X, U_m)$ |
| $Y = f_y(M, U_y)$ |



:::aside
Note: Independent errors can be dropped from the DAG!
:::

:::

:::{.column width=50%}


[**Truncated factorization**]{style="color:blue;"}


$$P(X,M,Y) = P(X) P(M|X) P (Y|M)$$

<br>

**Natural factorization**

(chain rule)

$P(X,M,Y) = P(X|M,Y)P(M|Y)P(Y)$

$P(X,M,Y) = P(M|X,Y)P(X|Y)P(Y)$

$P(X,M,Y) = P(M|X,Y)P(Y|X)P(X)$

$P(X,M,Y) = P(Y|X,M)P(X|M)P(M)$

:::

:::



## Alternative representations: forking paths

<br>

:::{.columns}

:::{.column width=50%}

[**Graphical model**]{style="color:blue;"}

$$X \leftarrow W \rightarrow Y$$

<br>

| [**Structural Equations**]{style="color:blue;"} |
|-----|
| $X = f_x(W, U_x)$ |
| $W = f_w(U_w)$ |
| $Y = f_y(W, U_y)$ |



:::aside
Note: Independent errors can be dropped from the DAG!
:::

:::

:::{.column width=50%}


[**Truncated factorization**]{style="color:blue;"}


$$P(X,W,Y) = P(W) P(X|W) P (Y|W)$$

<br>

**Natural factorization**

(chain rule)

$P(X,W,Y) = P(X|W,Y)P(W|Y)P(Y)$

$P(X,W,Y) = P(W|X,Y)P(X|Y)P(Y)$

$P(X,W,Y) = P(W|X,Y)P(Y|X)P(X)$

$P(X,W,Y) = P(Y|X,W)P(X|W)P(W)$

:::

:::



## Alternative representations: colliding paths

<br>

:::{.columns}

:::{.column width=50%}

[**Graphical model**]{style="color:blue;"}

$$X \rightarrow C \leftarrow Y$$

<br>

| [**Structural Equations**]{style="color:blue;"} |
|-----|
| $X = f_x(U_x)$ |
| $C = f_c(X, Y, U_c)$ |
| $Y = f_y(U_y)$ |



:::aside
Note: Independent errors can be dropped from the DAG!
:::

:::

:::{.column width=50%}


[**Truncated factorization**]{style="color:blue;"}


$$P(X,C,Y) = P(X) P(Y) P (C|X,Y)$$

<br>

**Natural factorization**

(chain rule)

$P(X,C,Y) = P(X|C,Y)P(C|Y)P(Y)$

$P(X,C,Y) = P(C|X,Y)P(X|Y)P(Y)$

$P(X,C,Y) = P(C|X,Y)P(Y|X)P(X)$

$P(X,C,Y) = P(Y|X,C)P(X|C)P(C)$

:::

:::

# Practice {background-color="#17a091"}


## Forking paths


:::{.columns}

:::{.column width=50%}


| Structural Equations |
|-----|
| $W = f_w(U_w)$ |
| $X = f_x(W, U_x)$ |
| $Y = f_y(W, X, U_y)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?
:::


:::{.column width=50%}


![](img\confounder1.png)

The DAG includes the following paths

$$X \rightarrow Y$$

$$X \leftarrow W \rightarrow Y$$
:::

:::

## Forking paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $W = f_w(U_w)$ |
| $X = f_x(W, U_x)$ |
| $Y = f_y(W, X, U_y)$ |


<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?
:::


:::{.column width=50%}

![](img\confounder3.png)

The following path is open

$$X \rightarrow Y$$

But this is now closed

$$X \leftarrow \boxed{W} \rightarrow Y$$
:::

:::


## Forking paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $W = f_w(U_w)$ |
| $X = f_x(W, U_x)$ |
| $Y = f_y(W, U_y)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?

Is there a causal effect of $X$ on $Y$?
:::


:::{.column width=50%}

![](img\confounder2.png)

The DAG includes the following path

$$X \leftarrow W \rightarrow Y$$
:::

:::
---


## Chaining paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $X = f_x(U_x)$ |
| $M = f_m(X, U_m)$ |
| $Y = f_y(M, X, U_y)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?

Is there a causal effect of $X$ on $Y$?
:::

:::{.column width=50%}

![](img\mediation1.png)

The DAG includes the following paths

$$X \rightarrow Y$$

$$X \rightarrow M \rightarrow Y$$
:::
:::
---


## Chaining paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $X = f_x(U_x)$ |
| $M = f_m(X, U_m)$ |
| $Y = f_y(M, X, U_y)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?

Is there a causal effect of $X$ on $Y$?
:::

:::{.column width=50%}

![](img\mediation2.png)

The DAG includes the following path

$$X \rightarrow Y$$

But this path is now closed

$$X \rightarrow \boxed{M} \rightarrow Y$$
:::

:::


## Colliding paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $X = f_x(U_x)$ |
| $Y = f_y(W, X, U_y)$ |
| $C = f_c(X, Y, U_c)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?

Is there a causal effect of $X$ on $Y$?
:::

:::{.column width=50%}

![](img\collider1.png)

The DAG includes the following paths

$$X \rightarrow Y$$

$$X \rightarrow C \leftarrow Y$$
:::

:::
---

## Colliding paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $X = f_x(U_x)$ |
| $Y = f_y(W, U_y)$ |
| $C = f_c(X, Y, U_c)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?

Is there a causal effect of $X$ on $Y$?
:::

:::{.column width=50%}

![](img\collider2.png)

The DAG includes the following path

$$X \rightarrow C \leftarrow Y$$
:::

:::
---

## Colliding paths

:::{.columns}

:::{.column width=50%}

| Structural Equations |
|-----|
| $X = f_x(U_x)$ |
| $Y = f_y(W, X, U_y)$ |
| $C = f_c(X, Y, U_c)$ |

<br>

Are $X$ and $Y$ marginally independent?

Are they conditionally independent?

Is there a causal effect of $X$ on $Y$?
:::

:::{.column width=50%}

![](img\collider3.png)

The DAG includes the following (open) path

$$X \rightarrow \boxed{C} \leftarrow Y$$
:::

:::


## Side note: are colliders that important? {background-color="#dce0ca"}

<br> 

One common question (and an area of debate among practitioners) is if colliders are really that important *in applied settings*. This is a hard question to answer, because, you know... we just don't know. 

But we know that they are **possible** and that their importance would depend on the structure of our causal graph.

A few compelling examples of collider bias in recent social sciences are discussed by:

* [Shalizi and Thomas (2011)](https://journals.sagepub.com/doi/abs/10.1177/0049124111404820) in the context of network homophily and contagion

* [Breen (2018)](https://academic.oup.com/esr/article/34/6/603/5094485) in the context of intergenerational mobility

* [Knox, Lowe and Mummolo (2020)](https://scholar.princeton.edu/jmummolo/publications/bias-built-how-administrative-records-mask-racially-biased-policing) in the context of police shootings

A great general introduction to the topic is offered by [Elwert and Winship (2014)](https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-071913-043455)

---


## Do-operator and interventions


Pearl introduced the $do-$operator to clearly distinguish between passive observations and interventions on the data generating process

In other words, is a form to make explicit the gap between interventional quantities and out more familiar conditional expectations

Causal identification corresponds to removing the $do-$operator from an expression, following the rules of $do-$calculus, reducing it to an observational quantity. If there is no equivalence, it means that the quantity of interest is not identified

Given the correspondence between a system of non-parametric structural equations and a given DAG, we can express the operation of **doing** as a *minimal surgery on the structural equation defining the treatment*

---

## Interventional graphs

:::{.columns}

:::{.column width=50%}

| Structural Causal Model |
|---|
| $Z_1 = f_{z1}(U_{z1})$ |
| $Z_2 = f_{z2}(U_{z2})$ |
| $W = f_{w}(Z_1, Z_2, U_{w})$ |
| $X = f_{z1}(Z_1, W, U_{x})$ |
| $Y = f_{y}(Z_2, W, U_{y})$ |

Let's start with the observational data generating process above

:::

:::{.column width=50%}
![](img\intervention1.png){width=65%}
:::

:::

---

## Interventional graphs

:::{.columns}

:::{.column width=50%}

| Structural Causal Model |
|---|
| $Z_1 = f_{z1}(U_{z1})$ |
| $Z_2 = f_{z2}(U_{z2})$ |
| $W = f_{w}(Z_1, Z_2, U_{w})$ |
| $X = x$ |
| $Y = f_{y}(Z_2, W, U_{y})$ |

Intervening in the model to make $X=x$ creates an interventional graph $G_{\bar{X}}$, in which all the incoming arrows into $X$ have been removed

:::

:::{.column width=50%}
![](img\intervention2.png){width=65%}
:::

:::

---



## Interventional graphs

:::{.columns}

:::{.column width=50%}


| Structural Causal Model |
|---|
| $Z_1 = f_{z1}(U_{z1})$ |
| $Z_2 = f_{z2}(U_{z2})$ |
| $W = f_{w}(Z_1, Z_2, U_{w})$ |
| $X = f_{z1}(Z_1, W, U_{x})$ |
| $Y = f_{y}(Z_2, W, U_{y})$ |

The purpose of an observational study is to allow only **causal paths** between the treatment $X$ and the outcome $Y$, and block all the **non causal paths**

:::

:::{.column width=50%}
![](img\intervention3.png){width=65%}

Adjusting for $W$ blocks a non-causal path, but opens a new one. 

$P(Y|do(x))$ is not identified conditioning on $W$ alone

:::

:::

---



## Interventional graphs

:::{.columns}

:::{.column width=50%}

| Structural Causal Model |
|---|
| $Z_1 = f_{z1}(U_{z1})$ |
| $Z_2 = f_{z2}(U_{z2})$ |
| $W = f_{w}(Z_1, Z_2, U_{w})$ |
| $X = f_{z1}(Z_1, W, U_{x})$  |
| $Y = f_{y}(Z_2, W, U_{y})$ |

The purpose of an observational study is to allow only **causal paths** between the treatment $X$ and the outcome $Y$, and block all the **non causal paths**
:::

:::{.column width=50%}
![](img\intervention4.png){width=65%}

Adjusting for $(Z_1,W)$ blocks all non-causal paths

$P(Y|do(x))$ is identified conditioning on $(Z_1,W)$
:::

:::

---



## Interventional graphs

:::{.columns}

:::{.column width=50%}

| Structural Causal Model |
|---|
| $Z_1 = f_{z1}(U_{z1})$ |
| $Z_2 = f_{z2}(U_{z2})$ |
| $W = f_{w}(Z_1, Z_2, U_{w})$ |
| $X = f_{z1}(Z_1, W, U_{x})$  |
| $Y = f_{y}(Z_2, W, U_{y})$ |

The purpose of an observational study is to allow only **causal paths** between the treatment $X$ and the outcome $Y$, and block all the **non causal paths**
:::

:::{.column width=50%}

![](img\intervention5.png){width=65%}

Adjusting for $(Z_2,W)$ also blocks all non-causal paths

$P(Y|do(x))$ is identified conditioning on $(Z_2,W)$
:::

:::

---

## Back-door Criterion (Pearl) {background-color="#002f87"}

<br>

What we just did can be summarized by the back-door criterion

A set of variables $W$ satisfied the back-door criterion relative to an ordered pair of variables $(X,Y)$ in a DAG $G$ if:

  (i) no node in $W$ is a descendant of $X$; and
  (ii) $W$ blocks every path between $X$ and $Y$ that contains an arrow into $X$

$\color{red}{\text{Important:}}$ satifying the backdoor criterion implies the unconfoundedness assumption
$$Y_x \indep X|W$$

The **back-door adjustment** (aka **g-formula**) indicates that we can recover the effect of $X$ on $Y$ adjusting for any $W$ that satisfy the backdoor criterion

$$P(Y|do(x)) = \sum_w P(Y|X,W)P(W)$$

:::aside
Pearl, *Causality*, pp.79-81
:::
---


## Short activity (5 mins) {background-color="#692044"}

Can you check, using the rules we practiced, if it is possible to identify the causal effect of $D$ on $Y$ in the following graphs?

Model 1: 

$D \rightarrow M$

$M \rightarrow Y$

$D \leftarrow (U) \rightarrow Y$

Where $(U)$ is unobserved, and therefore, it cannot be adjusted for


Model 2:

$D \rightarrow Y$

$Z \rightarrow D$

$D \leftarrow (U) \rightarrow Y$


Where $(U)$ is unobserved, and therefore, it cannot be adjusted for



## SCM: Key insights


* Causal identification is contingent on a given model encoding our assumptions

* Causal identification is finding an observational quantity that is equivalent to an interventional quantity

* Confounding (and bias) is a property of paths in a graph, not variables

* Confounding is relative to the pair $(X,Y)$, not just $X$

* It is not necessary to adjust for all *parents* of the treatment to block all backdoor paths

* Bias is not monotonically decreasing on the number of variables included

* $do-$calculus can be used to identify the effect of multiple interventions, to recover from missingness data, and to generalize study results.


## SCM: limitations

. . . 

Conditional on your model, most identification tasks are rather trivial (algorithmic). But before that you need to assume a certain DAG!

. . .

:::{.callout-warning}
## "Causality is in the model"
James Heckman (2005)
:::

. . . 

However, this is something that we always do! The only matter is how transparent are we about the assumptions we are making anyway

. . .

Another problem, more important for issues like mediation analysis and counterfactuals in general, is that we are sometimes making more assumptions that we are willing to

. . . 

For these cases, other causal (and graphical) models, like the [Single World Intervention Graphs](https://www.csss.washington.edu/Papers/wp128.pdf) (Richardson and Robins, 2013) can help

. . . 

Being fully non-parametric, certain canonical models are not identified using DAGs (like IVs). 

. . . 

However, this only shows that they require parametric assumptions, no matter how weak!

